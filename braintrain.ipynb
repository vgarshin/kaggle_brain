{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER = False\n",
    "KAGGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:28.749862Z",
     "iopub.status.busy": "2021-08-06T21:09:28.747805Z",
     "iopub.status.idle": "2021-08-06T21:09:32.249317Z",
     "shell.execute_reply": "2021-08-06T21:09:32.248676Z",
     "shell.execute_reply.started": "2021-08-02T17:58:27.498942Z"
    },
    "papermill": {
     "duration": 3.52828,
     "end_time": "2021-08-06T21:09:32.249512",
     "exception": false,
     "start_time": "2021-08-06T21:09:28.721232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "IIID_PATH = '../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D' if KAGGLE else './EfficientNet-PyTorch-3D'\n",
    "sys.path.append(IIID_PATH)\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning) \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' if KAGGLE else '1'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:32.298401Z",
     "iopub.status.busy": "2021-08-06T21:09:32.297704Z",
     "iopub.status.idle": "2021-08-06T21:09:32.341940Z",
     "shell.execute_reply": "2021-08-06T21:09:32.340728Z",
     "shell.execute_reply.started": "2021-08-02T17:58:27.510172Z"
    },
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.071767,
     "end_time": "2021-08-06T21:09:32.342078",
     "exception": false,
     "start_time": "2021-08-06T21:09:32.270311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VER = 'v11'\n",
    "DATA_PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification' if KAGGLE else './data'\n",
    "MDLS_PATH = f'../input/brain-models-{VER}' if KAGGLE else f'./models_{VER}'\n",
    "MRI_TYPES = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "if INFER:\n",
    "    with open(f'{MDLS_PATH}/config.json', 'r') as file:\n",
    "        CONFIG = json.load(file)\n",
    "    print('config loaded:', CONFIG)\n",
    "else:\n",
    "    CONFIG = {\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'batch_size': 10,\n",
    "        'img_size': 300, # 224, 240, 260, 300, 380, 456, 528, 600\n",
    "        'num_images': 64,\n",
    "        'bbone': 'efficientnet-b3',\n",
    "        'auc': False,\n",
    "        'folds': 5,\n",
    "        'epochs': 100,\n",
    "        'lr': 1e-3,\n",
    "        'patience': 20,\n",
    "        'seed': 2021\n",
    "    }\n",
    "    if not os.path.exists(MDLS_PATH):\n",
    "        os.mkdir(MDLS_PATH)\n",
    "    with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "        json.dump(CONFIG, file)\n",
    "\n",
    "def seed_all(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return random_state    \n",
    "\n",
    "random_state = seed_all(CONFIG['seed'])\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:32.436940Z",
     "iopub.status.busy": "2021-08-06T21:09:32.436132Z",
     "iopub.status.idle": "2021-08-06T21:09:33.517999Z",
     "shell.execute_reply": "2021-08-06T21:09:33.517391Z",
     "shell.execute_reply.started": "2021-08-02T17:58:27.52446Z"
    },
    "papermill": {
     "duration": 1.115144,
     "end_time": "2021-08-06T21:09:33.518168",
     "exception": false,
     "start_time": "2021-08-06T21:09:32.403024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dicom_image(path, img_size=256, voi_lut=True, rotate=0):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "    if rotate > 0:\n",
    "        rot_choices = [0, \n",
    "                       cv2.ROTATE_90_CLOCKWISE, \n",
    "                       cv2.ROTATE_90_COUNTERCLOCKWISE, \n",
    "                       cv2.ROTATE_180]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data.astype(np.float32())\n",
    "\n",
    "def load_dicom_images_3d(scan_id, num_imgs=64, img_size=256, \n",
    "                         mri_type='FLAIR', split='train', rotate=0):\n",
    "    files = sorted(\n",
    "        glob.glob(f'{DATA_PATH}/{split}/{scan_id}/{mri_type}/*.dcm'), \n",
    "        key=lambda var: [int(x) if x.isdigit() else x \n",
    "                         for x in re.findall(r'[^0-9]|[0-9]+', var)]\n",
    "    )\n",
    "    middle, num_imgs2 = len(files) // 2, num_imgs // 2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    img3d = np.stack([load_dicom_image(f, img_size, rotate=rotate) \n",
    "                      for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]), \n",
    "                          dtype=np.float32())\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis=-1)\n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)\n",
    "    return np.expand_dims(img3d, 0)\n",
    "\n",
    "img = load_dicom_images_3d('00000')\n",
    "print(img.shape)\n",
    "print(np.min(img), np.max(img), np.mean(img), np.median(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:33.719903Z",
     "iopub.status.busy": "2021-08-06T21:09:33.718836Z",
     "iopub.status.idle": "2021-08-06T21:09:33.763678Z",
     "shell.execute_reply": "2021-08-06T21:09:33.764263Z",
     "shell.execute_reply.started": "2021-08-02T17:58:27.996423Z"
    },
    "papermill": {
     "duration": 0.072485,
     "end_time": "2021-08-06T21:09:33.764501",
     "exception": false,
     "start_time": "2021-08-06T21:09:33.692016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}/train_labels.csv')\n",
    "print(df.shape, df['MGMT_value'].sum())\n",
    "display(df.head())\n",
    "skf = StratifiedKFold(CONFIG['folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "df['fold'] = -1\n",
    "for i, (train_idxs, val_idxs) in enumerate(skf.split(df, df['MGMT_value'])):\n",
    "    df.loc[val_idxs, 'fold'] = i\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:33.927629Z",
     "iopub.status.busy": "2021-08-06T21:09:33.925330Z",
     "iopub.status.idle": "2021-08-06T21:09:33.928623Z",
     "shell.execute_reply": "2021-08-06T21:09:33.929128Z",
     "shell.execute_reply.started": "2021-08-02T17:58:28.035841Z"
    },
    "papermill": {
     "duration": 0.038942,
     "end_time": "2021-08-06T21:09:33.929307",
     "exception": false,
     "start_time": "2021-08-06T21:09:33.890365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BrainDataset(torch_data.Dataset):\n",
    "    def __init__(self, paths, img_size, targets=None, mri_type=None, \n",
    "                 lbl_smth=.001, split='train', aug=False, albu=None):\n",
    "        self.paths = paths\n",
    "        self.img_size = img_size\n",
    "        self.targets = targets\n",
    "        self.mri_type = mri_type\n",
    "        self.lbl_smth = lbl_smth\n",
    "        self.split = split\n",
    "        self.aug = aug\n",
    "        self.albu = albu\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        scan_id = self.paths[index]\n",
    "        if self.targets is None:\n",
    "            data = load_dicom_images_3d(\n",
    "                str(scan_id).zfill(5), \n",
    "                img_size=self.img_size,\n",
    "                mri_type=self.mri_type[index], \n",
    "                split=self.split\n",
    "            )\n",
    "        else:\n",
    "            if self.aug:\n",
    "                rotation = np.random.randint(0, 4)\n",
    "            else:\n",
    "                rotation = 0\n",
    "            data = load_dicom_images_3d(\n",
    "                str(scan_id).zfill(5), \n",
    "                img_size=self.img_size,\n",
    "                mri_type=self.mri_type[index], \n",
    "                split='train', \n",
    "                rotate=rotation\n",
    "            )\n",
    "            if self.albu:\n",
    "                frozen = albu(image=data[0, :, :, 0])\n",
    "                data[0, :, :, 0] = frozen['image']\n",
    "                for i in range(1, CONFIG['num_images']):\n",
    "                    data[0, :, :, i] = A.ReplayCompose.replay(\n",
    "                        frozen['replay'], \n",
    "                        image=data[0, :, :, i]\n",
    "                    )['image']\n",
    "        if self.targets is None:\n",
    "            return {'X': torch.tensor(data).float(), 'id': scan_id}\n",
    "        else:\n",
    "            y = torch.tensor(\n",
    "                abs(self.targets[index] - self.lbl_smth), \n",
    "                dtype=torch.float\n",
    "            )\n",
    "            return {'X': torch.tensor(data).float(), 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "albu = A.ReplayCompose([\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=.2, \n",
    "            contrast_limit=.2, \n",
    "            p=1), \n",
    "        A.RandomGamma(p=1)\n",
    "    ], p=.5),\n",
    "    A.Blur(blur_limit=3, p=.5),\n",
    "    A.GaussNoise(.002, p=.5),\n",
    "    A.OneOf([\n",
    "           A.ElasticTransform(\n",
    "               alpha=120, \n",
    "               sigma=120 * .05, \n",
    "               alpha_affine=120 * .03, \n",
    "               p=.5),\n",
    "           A.GridDistortion(p=.5),\n",
    "       ], p=.5),\n",
    "    A.ShiftScaleRotate(p=.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'MRI_Type'] = 'FLAIR'\n",
    "dataset_show = BrainDataset(\n",
    "    paths=df['BraTS21ID'].values, \n",
    "    img_size=CONFIG['img_size'],\n",
    "    targets=df['MGMT_value'].values, \n",
    "    mri_type=df['MRI_Type'].values,\n",
    "    aug=True,\n",
    "    albu=albu\n",
    ")\n",
    "data_show = dataset_show.__getitem__(0)\n",
    "\n",
    "n_imgs = 8\n",
    "print('test X: ', data_show['X'].shape)\n",
    "print('test y: ', data_show['y'].shape)\n",
    "fig, axes = plt.subplots(figsize=(16, 4), nrows=1, ncols=n_imgs)\n",
    "for j in range(n_imgs):\n",
    "    axes[j].imshow(data_show['X'][0][:, :, j].numpy())\n",
    "    axes[j].set_title(data_show['y'].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:33.981107Z",
     "iopub.status.busy": "2021-08-06T21:09:33.980182Z",
     "iopub.status.idle": "2021-08-06T21:09:33.985353Z",
     "shell.execute_reply": "2021-08-06T21:09:33.984847Z",
     "shell.execute_reply.started": "2021-08-02T17:58:28.049391Z"
    },
    "papermill": {
     "duration": 0.034044,
     "end_time": "2021-08-06T21:09:33.985502",
     "exception": false,
     "start_time": "2021-08-06T21:09:33.951458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BrainModel(nn.Module): \n",
    "    def __init__(self, bbone='efficientnet-b0'):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet3D.from_name(\n",
    "            bbone, \n",
    "            override_params={'num_classes': 2}, \n",
    "            in_channels=1\n",
    "        )\n",
    "        n_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Linear(\n",
    "            in_features=n_features, \n",
    "            out_features=1, \n",
    "            bias=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:34.051746Z",
     "iopub.status.busy": "2021-08-06T21:09:34.047795Z",
     "iopub.status.idle": "2021-08-06T21:09:34.055426Z",
     "shell.execute_reply": "2021-08-06T21:09:34.054766Z",
     "shell.execute_reply.started": "2021-08-02T17:58:28.059124Z"
    },
    "papermill": {
     "duration": 0.048362,
     "end_time": "2021-08-06T21:09:34.055577",
     "exception": false,
     "start_time": "2021-08-06T21:09:34.007215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BrainTrainer:\n",
    "    def __init__(self, model, device, optimizer, scheduler, \n",
    "                 criterion, auc_flag=True):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        self.auc_flag = auc_flag\n",
    "        if auc_flag:\n",
    "            self.best_val_auc = 0\n",
    "        else:\n",
    "            self.best_val_loss = np.inf\n",
    "        self.lastmodel = None\n",
    "        \n",
    "    def fit(self, epochs, train_loader, val_loader, save_path, max_patience):     \n",
    "        n_patience = 0\n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message('EPOCH: {}', n_epoch)\n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            val_loss, val_auc, val_time = self.val_epoch(val_loader)\n",
    "            self.info_message(\n",
    "                'epoch train: {} | loss: {:.4f} | time: {:.2f} sec',\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            self.info_message(\n",
    "                'epoch val: {} | loss: {:.4f} | auc: {:.4f} | time: {:.2f} sec',\n",
    "                n_epoch, val_loss, val_auc, val_time\n",
    "            )\n",
    "            if self.auc_flag:\n",
    "                if self.best_val_auc < val_auc: \n",
    "                    self.save_model(n_epoch, save_path, val_loss, val_auc)\n",
    "                    self.info_message(\n",
    "                        'val auc improved {:.2f} -> {:.2f} | saved model to \"{}\"', \n",
    "                        self.best_val_auc, val_auc, self.lastmodel\n",
    "                    )\n",
    "                    self.best_val_auc = val_auc\n",
    "                    n_patience = 0\n",
    "                else:\n",
    "                    n_patience += 1\n",
    "            else:\n",
    "                if self.best_val_loss > val_loss: \n",
    "                    self.save_model(n_epoch, save_path, val_loss, val_auc)\n",
    "                    self.info_message(\n",
    "                        'val loss improved {:.4f} -> {:.4f} | saved model to \"{}\"', \n",
    "                        self.best_val_loss, val_loss, self.lastmodel\n",
    "                    )\n",
    "                    self.best_val_loss = val_loss\n",
    "                    n_patience = 0\n",
    "                else:\n",
    "                    n_patience += 1\n",
    "            if n_patience >= max_patience:\n",
    "                self.info_message(\n",
    "                    '\\nno improvement for last {} epochs', \n",
    "                    n_patience\n",
    "                )\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            with torch.cuda.amp.autocast():\n",
    "                X = batch['X'].to(self.device)\n",
    "                targets = batch['y'].to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "                self.scheduler.step()\n",
    "                sum_loss += loss.detach().item()\n",
    "                self.info_message(\n",
    "                    'train step {}/{} | train loss: {:.4f}           ',\n",
    "                    step, len(train_loader), sum_loss / step, end='\\r'\n",
    "                )\n",
    "        return sum_loss / len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def val_epoch(self, val_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "        for step, batch in enumerate(val_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                X = batch['X'].to(self.device)\n",
    "                targets = batch['y'].to(self.device)\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                sum_loss += loss.detach().item()\n",
    "                y_all.extend(batch[\"y\"].tolist())\n",
    "                outputs_all.extend(outputs.tolist())\n",
    "            self.info_message(\n",
    "                'val step {}/{} | val loss: {:.4f}               ', \n",
    "                step, len(val_loader), sum_loss / step, end='\\r'\n",
    "            )\n",
    "        y_all = [1 if x > 0.5 else 0 for x in y_all]\n",
    "        auc = roc_auc_score(y_all, outputs_all)\n",
    "        return sum_loss / len(val_loader), auc, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path, loss, auc):\n",
    "        self.lastmodel = f'{MDLS_PATH}/{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}.pth'\n",
    "        dict_save = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'n_epoch': n_epoch,\n",
    "        }\n",
    "        if self.auc_flag:\n",
    "            dict_save[ 'best_val_auc'] = self.best_val_auc\n",
    "        else:\n",
    "            dict_save[ 'best_val_loss'] = self.best_val_loss\n",
    "        torch.save(dict_save, self.lastmodel)\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end='\\n'):\n",
    "        print(message.format(*args), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T21:09:34.160760Z",
     "iopub.status.busy": "2021-08-06T21:09:34.159960Z",
     "iopub.status.idle": "2021-08-07T01:30:29.215916Z",
     "shell.execute_reply": "2021-08-07T01:30:29.215093Z",
     "shell.execute_reply.started": "2021-08-02T17:58:28.081487Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 15655.094801,
     "end_time": "2021-08-07T01:30:29.216072",
     "exception": false,
     "start_time": "2021-08-06T21:09:34.121271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mri_type(df_train, df_val, mri_type, device, \n",
    "                   epochs, patience, batch_size):\n",
    "    if mri_type == 'all':\n",
    "        train_list = []\n",
    "        val_list = []\n",
    "        for mri_type in mri_types:\n",
    "            df_train.loc[:, 'MRI_Type'] = mri_type\n",
    "            train_list.append(df_train.copy())\n",
    "            df_val.loc[:, 'MRI_Type'] = mri_type\n",
    "            val_list.append(df_val.copy())\n",
    "        df_train = pd.concat(train_list)\n",
    "        df_val = pd.concat(val_list)\n",
    "    else:\n",
    "        df_train.loc[:, 'MRI_Type'] = mri_type\n",
    "        df_val.loc[:, 'MRI_Type'] = mri_type\n",
    "    print('train:', df_train.shape, '| val:', df_val.shape)\n",
    "    display(df_train.head())\n",
    "    train_dataset = BrainDataset(\n",
    "        paths=df_train['BraTS21ID'].values, \n",
    "        img_size=CONFIG['img_size'],\n",
    "        targets=df_train['MGMT_value'].values, \n",
    "        mri_type=df_train['MRI_Type'].values,\n",
    "        aug=True,\n",
    "        albu=albu\n",
    "    )\n",
    "    val_dataset = BrainDataset(\n",
    "        paths=df_val['BraTS21ID'].values, \n",
    "        img_size=CONFIG['img_size'],\n",
    "        targets=df_val['MGMT_value'].values,\n",
    "        mri_type=df_val['MRI_Type'].values\n",
    "    )\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "    val_loader = torch_data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=8\n",
    "    )\n",
    "    model = BrainModel(bbone=CONFIG['bbone'])\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        CONFIG['epochs']\n",
    "    )\n",
    "    criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "    trainer = BrainTrainer(\n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        scheduler,\n",
    "        criterion,\n",
    "        auc_flag=CONFIG['auc']\n",
    "    )\n",
    "    history = trainer.fit(\n",
    "        epochs, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        save_path=f'{mri_type}', \n",
    "        max_patience=patience\n",
    "    )\n",
    "    return trainer.lastmodel\n",
    "\n",
    "if INFER:\n",
    "    with open(f'{MDLS_PATH}/modelfiles.json', 'r') as file:\n",
    "        modelfiles = json.load(file)\n",
    "    print(\"model's list loaded:\", modelfiles)\n",
    "else:\n",
    "    modelfiles = None\n",
    "if not modelfiles:\n",
    "    fold_num = 0 \n",
    "    train_idxs = np.where((df['fold'] != fold_num))[0]\n",
    "    val_idxs = np.where((df['fold'] == fold_num))[0]\n",
    "    df_train = df.loc[train_idxs]\n",
    "    df_val = df.loc[val_idxs]\n",
    "    modelfiles = [\n",
    "        train_mri_type(\n",
    "            df_train, \n",
    "            df_val, \n",
    "            m, \n",
    "            device=CONFIG['device'], \n",
    "            epochs=CONFIG['epochs'],\n",
    "            patience=CONFIG['patience'],\n",
    "            batch_size=CONFIG['batch_size']\n",
    "        ) \n",
    "        for m in MRI_TYPES\n",
    "    ]\n",
    "    print(modelfiles)\n",
    "    with open(f'{MDLS_PATH}/modelfiles.json', 'w') as file:\n",
    "        json.dump(modelfiles, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfiles = [f'{MDLS_PATH}/{x.split(\"/\")[-1]}' for x in modelfiles]\n",
    "allmodelfiles = [f'{MDLS_PATH}/{x}' for x in os.listdir(MDLS_PATH) if '.pth' in x]\n",
    "for file_path in allmodelfiles:\n",
    "    if file_path not in modelfiles:\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.00136,
     "end_time": "2021-08-07T01:30:33.207057",
     "exception": false,
     "start_time": "2021-08-07T01:30:31.205697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T01:30:37.525934Z",
     "iopub.status.busy": "2021-08-07T01:30:37.525139Z",
     "iopub.status.idle": "2021-08-07T01:30:37.528919Z",
     "shell.execute_reply": "2021-08-07T01:30:37.528355Z"
    },
    "papermill": {
     "duration": 2.008519,
     "end_time": "2021-08-07T01:30:37.529047",
     "exception": false,
     "start_time": "2021-08-07T01:30:35.520528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(model_file, df, mri_type, split, device, batch_size):\n",
    "    print('PREDICT:', model_file, mri_type, df.shape)\n",
    "    df.loc[:, 'MRI_Type'] = mri_type\n",
    "    pred_dataset = BrainDataset(\n",
    "        paths=df.index.values, \n",
    "        img_size=CONFIG['img_size'],\n",
    "        mri_type=df['MRI_Type'].values,\n",
    "        split=split\n",
    "    )\n",
    "    pred_loader = torch_data.DataLoader(\n",
    "        pred_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "    model = BrainModel(bbone=CONFIG['bbone'])\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(model_file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    ids = []\n",
    "    for i, batch in enumerate(pred_loader, start=1):\n",
    "        print(f'{i}/{len(pred_loader)}', end='\\r')\n",
    "        with torch.no_grad():\n",
    "            tmp_pred = torch.sigmoid(\n",
    "                model(batch['X'].to(device))\n",
    "            ).cpu().numpy().squeeze()\n",
    "            if tmp_pred.size == 1:\n",
    "                y_pred.append(tmp_pred)\n",
    "            else:\n",
    "                y_pred.extend(tmp_pred.tolist())\n",
    "            ids.extend(batch['id'].numpy().tolist()) \n",
    "    df_pred = pd.DataFrame({'BraTS21ID': ids, 'MGMT_value': y_pred}) \n",
    "    df_pred = df_pred.set_index('BraTS21ID')\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.960893,
     "end_time": "2021-08-07T01:30:41.489693",
     "exception": false,
     "start_time": "2021-08-07T01:30:39.528800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df.loc[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T01:30:45.787509Z",
     "iopub.status.busy": "2021-08-07T01:30:45.773150Z",
     "iopub.status.idle": "2021-08-07T01:33:56.926710Z",
     "shell.execute_reply": "2021-08-07T01:33:56.927246Z"
    },
    "papermill": {
     "duration": 193.460011,
     "end_time": "2021-08-07T01:33:56.927468",
     "exception": false,
     "start_time": "2021-08-07T01:30:43.467457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if INFER:\n",
    "    print('infer mode, no validation')\n",
    "else:\n",
    "    df_val = df_val.set_index('BraTS21ID')\n",
    "    df_val['MGMT_pred'] = 0\n",
    "    for m, mtype in zip(modelfiles, MRI_TYPES):\n",
    "        preds = infer(m, df_val, mtype, 'train', \n",
    "                      CONFIG['device'], CONFIG['batch_size'])\n",
    "        df_val['MGMT_pred'] += preds['MGMT_value']\n",
    "    df_val['MGMT_pred'] /= len(modelfiles)\n",
    "    auc = roc_auc_score(df_val['MGMT_value'], df_val['MGMT_pred'])\n",
    "    print(f'validation ensemble AUC: {auc:.4f}')\n",
    "    sns.displot(df_val['MGMT_pred'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.109878,
     "end_time": "2021-08-07T01:34:01.104043",
     "exception": false,
     "start_time": "2021-08-07T01:33:58.994165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T01:34:05.509372Z",
     "iopub.status.busy": "2021-08-07T01:34:05.508494Z",
     "iopub.status.idle": "2021-08-07T01:36:36.165870Z",
     "shell.execute_reply": "2021-08-07T01:36:36.165262Z"
    },
    "papermill": {
     "duration": 152.695794,
     "end_time": "2021-08-07T01:36:36.166098",
     "exception": false,
     "start_time": "2021-08-07T01:34:03.470304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv(f'{DATA_PATH}/sample_submission.csv', \n",
    "                      index_col='BraTS21ID')\n",
    "df_subm['MGMT_value'] = 0\n",
    "for m, mtype in zip(modelfiles, MRI_TYPES):\n",
    "    preds = infer(m, df_subm, mtype, 'test',\n",
    "                  CONFIG['device'], CONFIG['batch_size'])\n",
    "    df_subm['MGMT_value'] += preds['MGMT_value']\n",
    "df_subm['MGMT_value'] /= len(modelfiles)\n",
    "display(df_subm.head())\n",
    "df_subm['MGMT_value'].to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T01:36:45.173157Z",
     "iopub.status.busy": "2021-08-07T01:36:45.155614Z",
     "iopub.status.idle": "2021-08-07T01:36:45.496980Z",
     "shell.execute_reply": "2021-08-07T01:36:45.496427Z"
    },
    "papermill": {
     "duration": 2.659915,
     "end_time": "2021-08-07T01:36:45.497128",
     "exception": false,
     "start_time": "2021-08-07T01:36:42.837213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(df_subm['MGMT_value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.208406,
     "end_time": "2021-08-07T01:36:49.985800",
     "exception": false,
     "start_time": "2021-08-07T01:36:47.777394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16055.008744,
   "end_time": "2021-08-07T01:36:55.228844",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-06T21:09:20.220100",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
